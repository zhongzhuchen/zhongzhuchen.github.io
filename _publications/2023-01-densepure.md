---
title: "DensePure: Understanding Diffusion Models for Adversarial Robustness"
collection: publications
category: conferences
permalink: /publication/2023-densepure
excerpt: 'State-of-the-art diffusion-based defense against adversarial attacks achieving certified robustness.'
date: 2023-01-01
venue: 'The Eleventh International Conference on Learning Representations (ICLR 2023)'
paperurl: 'https://openreview.net/forum?id=p7hvOJ6Gq0i'
citation: 'Chaowei Xiao*, Zhongzhu Chen*, Kun Jin*, Jiongxiao Wang*, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, and Dawn Song. (2023). &quot;DensePure: Understanding Diffusion Models for Adversarial Robustness.&quot; <i>ICLR 2023</i>.'
---

This paper introduces DensePure, a novel defense mechanism that leverages diffusion models for adversarial robustness. By understanding how diffusion models purify adversarial perturbations, we achieve state-of-the-art certified robustness on image classification tasks.

**Key Contributions:**
- Theoretical analysis of diffusion models for adversarial purification
- DensePure defense achieving superior certified robustness
- Extensive empirical validation on benchmark datasets

*Equal contribution
